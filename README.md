# NatyaNirmiti: Subtitle Generation for Bharatanatyam Poses                                                                       

## Overview

NatyaNirmiti aims to recognize and classify Bharatanatyam dance poses from images using machine learning techniques. The project processes video data, extracts features, trains a model, evaluates it, and makes predictions to identify dance poses.

## Table of Contents

1. [Project Structure](#project-structure)
2. [Setup](#setup)
3. [Running the Scripts](#running-the-scripts)
   - [Preprocess Images](#preprocess-images)
   - [Extract Features](#extract-features)
   - [Train Model](#train-model)
   - [Evaluate Model](#evaluate-model)
   - [Make Predictions](#make-predictions)
4. [Next Steps](#next-steps)
5. [Acknowledgments](#acknowledgments)

## Project Structure

```plaintext
NatyaNirmithi_Bharathanatyam_pose_detection/
├── bharatanatyam-env/  # Virtual environment
├── data/               # Data folder
│   ├── raw/            # Raw images and videos
│   └── processed/      # Processed images
├── models/             # Trained models
├── src/                # Source scripts
│   ├── preprocess.py   # Preprocessing script
│   ├── feature_extraction.py  # Feature extraction script
│   ├── train.py        # Training script
│   ├── evaluate.py     # Evaluation script
│   └── predict.py      # Prediction script
└── README.md           # This README file
```


## Setup

1. *Clone the repository*:

    bash
    git clone [https://github.com/pathu10/NatyaNirmithi_Bharathanatyam_pose_detection.git](https://github.com/pathu10/NatyaNirmithi_Bharathanatyam_pose_detection)

   cd NatyaNirmithi_Bharathanatyam_pose_detection
    

3. *Create and activate the virtual environment*:

    bash
    python -m venv bharatanatyam-env

    - *For PowerShell*:

      powershell
      .\bharatanatyam-env\Scripts\Activate.ps1    

    - *For Command Prompt*:

      cmd
      bharatanatyam-env\Scripts\activate.bat
      

4. *Install the required packages*:

    bash
    pip install -r requirements.txt
    

## Running the Scripts

### Preprocess Images

bash
python src/preprocess.py


This script converts raw video files into RGB format images and extracts frames.

### Extract Features

bash
python src/feature_extraction.py


This script computes Motion History Images (MHI) and Histograms of Gradient of MHI (HoGMHI) as features from the processed images.

### Train Model

bash
python src/train.py


This script trains the model using the extracted features and saves the trained model.

### Evaluate Model

bash
python src/evaluate.py


This script evaluates the performance of the trained model using accuracy and other metrics.

### Make Predictions

bash
python src/predict.py --image_path <path_to_image>


This script predicts the Bharatanatyam pose for a given input image.

## Next Steps

1. *Collect more data*: More data will help improve the model's accuracy.
2. *Experiment with CNNs*: Implement a Convolutional Neural Network (CNN) for better performance.
3. *Tune Hyperparameters*: Optimize the model's hyperparameters for better accuracy.

## Acknowledgments

We would like to thank the authors of the referenced papers and datasets for their valuable contributions, which have significantly aided in the development of this project.

1. Bhuyan, H.B., Killi, J., Dash, J.K., & Das, P. (2022). Motion Recognition in Bharatanatyam Dance. IEEE Access, 10(2), 1-1.
- DOI: [10.1109/ACCESS.2022.3184735](https://doi.org/10.1109/ACCESS.2022.3184735)
2. Bobick, A.F., & Davis, J.W. (2001). The Recognition of Human Movement Using Temporal Templates. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(3), 257-267.
- DOI: [10.1109/34.910878](https://doi.org/10.1109/34.910878)
3. Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., ... & Blake, A. (2011). Real-time Human Pose Recognition in Parts from Single Depth Images. IEEE Transactions on Multimedia, 19(5), 774-785.
- DOI: [10.1109/CVPR.2011.5995316](https://doi.org/10.1109/CVPR.2011.5995316)
4. Dalal, N., & Triggs, B. (2005). Histograms of Oriented Gradients for Human Detection. CVPR'05. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1, 886-893.
- DOI: [10.1109/CVPR.2005.177](https://doi.org/10.1109/CVPR.2005.177)
5. Zhu, Z., & Kanade, T. (2020). Recognizing Dance Movements with Deep Learning. Pattern Recognition Letters, 136, 163-170.
- DOI: [10.1016/j.patrec.2020.06.010](https://doi.org/10.1016/j.patrec.2020.06.010)
6. Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20(3), 273-297.
- DOI: [10.1007/BF00994018](https://doi.org/10.1007/BF00994018)
7. LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.
- DOI: [10.1109/5.726791](https://doi.org/10.1109/5.726791)
8. Toshev, A., & Szegedy, C. (2014). DeepPose: Human Pose Estimation via Deep Neural Networks. CVPR 2014: IEEE Conference on Computer Vision and Pattern Recognition, 1653-1660.
- DOI: [10.1109/CVPR.2014.214](https://doi.org/10.1109/CVPR.2014.214)
9. Kalaimani, M., & Sigappi, A.N. (2023). Posture Recognition in Bharathanatyam Images using 2D-CNN. Data & Metadata, 2(136), 1-10.
- DOI: [10.56294/dm2023136](https://doi.org/10.56294/dm2023136)
10. Singh, A., & Subramanian, R. (2022). Cultural Dance Posture Analysis using Machine Learning. Journal of Cultural Heritage, 51, 24-32.
- DOI: [10.1016/j.culher.2021.10.003](https://doi.org/10.1016/j.culher.2021.10.003)
11. Mitra, S., & Acharya, T. (2021). Automated Feedback Systems for Dance Education. Educational Technology & Society, 24(3), 213-224.
Available_at:[ResearchGate](https://www.researchgate.net/publication/349634599_Automated_Feedback_Systems_for_Dance_Education)
12. Kender, J.R., & Chou, P.A. (2018). Preservation of Cultural Heritage through Technology. Digital Humanities Quarterly, 12(3), 19-28.
Available_at:[DigitalHumanitiesQuarterly](http://www.digitalhumanities.org/dhq/vol/12/3/000256/000256.html)
13. Kim, K., & Song, J. (2020). Interactive Learning Systems for Dance. Computers & Education, 149, 103832.
DOI: [10.1016/j.compedu.2020.103832](https://doi.org/10.1016/j.compedu.2020.103832)
14. Zhang, Z., & Lu, H. (2019). Mapping Traditional Dance Movements to Modern Technology. International Journal of Arts and Technology, 12(2), 97-115.
- DOI: [10.1504/IJART.2019.098731](https://doi.org/10.1504/IJART.2019.098731)
15. Wang, J., & Wu, Y. (2021). Deep Learning Approaches for Dance Recognition. Journal of AI Research, 70, 299-324.
- DOI: [10.1613/jair.1.12322](https://doi.org/10.1613/jair.1.12322)
---
